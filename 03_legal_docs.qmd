
Un cas important est l'[Arrêté Interministériel n° 18633/2008/MEFT/MEM du 17 octobre 2008 portant mise en protection temporaire globale des sites visés par l’Arrêté interministériel n° 17914 du 18 octobre 2006 et levant la suspension de l’octroi des permis miniers et forestiers pour certains sites.](https://faolex.fao.org/docs/pdf/Mad173201.pdf) Cette décision s'applique à 97 nouvelles aires protégées en cours de création et 29 sites prioritaires pour la biodiversité et la gestion forestière.

Ce dernier a été amendé par l'[Arrêté interministériel n° 52005/2010 du 20 décembre 2010 modifiant l'arrêté interministériel Mine-Forêts n°18633 du 17 octobre 2008 portant mise en protection temporaire globale des sites visés par l’arrêté n°17914 du 18 octobre 2006 et levant la suspension de l’octroi des permis miniers et forestiers pour certains sites.](https://faolex.fao.org/docs/pdf/mad142467.pdf) Cette décision s'applique à 95 aires protégées (24 ayant déjà un statut de protection temporaire).

Ces deux textes concernent une liste très étendu de sites potentiels, qui ne sont pas nommément listés dans le texte. On a juste une carte (peu précise) et une somme de zones concernées (en nombre et en surface).

```{r}
library(rvest)
library(tidyverse)

# Specify the source repository 
data_dir <- "sources/"
# Directory containing the HTML files
input_dir <- paste0(data_dir, "Décrets/CNLEGIS")


# Columns to select
keep_columns <- c(
  "DATE(S)", "DATE TEXTES", "TEXTE(S)", "TYPE", "NUM TEXTE", "NUM", "OBJET",
  "OBJET MG", "NUM JO", "DATE JO", "DATE JO FR", "PAGE JO", "ETAT", "NOTE(S)",
  "NOTES MG", "DOC PDF FR", "DOC PDF MG", "MINISTERE(S)", "id", "HTML FR", 
  "HTML MG")
keep_types <- c(
  "Constitution", "Loi constitutionnelle", "Loi organique", "Loi",
  "Ordonnance", "Décret", "Arrêté", "Circulaire", "Décision",
  "Instruction", "Note", "Délibération", "Arrêt", "Avis", "Palmarès",
  "Procès verbal", "Exposé des motifs de la loi", "Jugement", "Déclaration")

# Function to clean column names
clean_column_names <- function(names) {
  names %>%
    str_replace_all("\\(|\\)", "") %>%  # Remove parentheses
    str_replace_all(" ", "_") %>%      # Replace spaces with underscores
    str_to_lower()                     # Convert to lowercase
}



# Function to extract the desired table from a single HTML file
extract_table <- function(file_path) {
  # Read the HTML file
  html <- read_html(file_path)
  
  # Extract the table
  table <- html %>%
    html_node("table#Lst_docs") %>%
    html_table(fill = TRUE)
  
  
  # Select the relevant columns
  selected_columns <- table %>%
    select(all_of(keep_columns)) %>%
    filter(TYPE %in% keep_types)
  
   colnames(selected_columns) <- clean_column_names(colnames(selected_columns))

      # Ensure all columns are converted to text
   selected_columns<- selected_columns %>%
     mutate(across(everything(), as.character))
   
  return(selected_columns)
}

# Get a list of all HTML files in the directory
html_files <- list.files(input_dir, pattern = "\\.html$", full.names = TRUE)

# Apply the extraction function to all files
all_results <- map_dfr(html_files, extract_table)

```

Classification du type

```{r}
# Add typology columns
class_results <- all_results %>%
  mutate(
    creation_definitive = str_detect(
      textes, regex("(?<!en )(création|crétion de l'aire protégée)", 
                    ignore_case = TRUE)),
    modifiant = str_detect(textes, regex("modifiant", ignore_case = TRUE)),
    prorogation = str_detect(textes, regex("prorog", ignore_case = TRUE)),
    delegation_gestion = str_detect(
      textes, regex("délégation de gestion", ignore_case = TRUE)),
    mise_protection_temporaire = str_detect(
      textes, regex("protection temporaire", ignore_case = TRUE)),

    nomination = str_detect(textes, regex("nomination", ignore_case = TRUE))) %>%
mutate(
    total_true = rowSums(select(., creation_definitive:nomination), na.rm = TRUE),
    concatenated_true = pmap_chr(
      select(., creation_definitive:nomination),
      ~ paste(names(which(c(...))), collapse = ", ")
    ),
    .before = everything()
  ) %>%
  filter(!(total_true == 0)) %>%
  filter(!(total_true == 1 & nomination)) %>% # On enlève le copil Sydney
  filter(!(str_detect(textes, "fonctionnement du Comité de Pilotage"))) %>%
  filter(!(str_detect(textes, "fonctionnement de la Commission"))) %>%
  filter(!(str_detect(textes, "organisation du Comité")))
```

On extrait le nom des aires protégées.

```{r}
   

class_results <- class_results %>%
  mutate(
    pa = str_extract(
      textes, regex("[\"«](.*?)[\"»,]|nommée\\s*(.*?)[»,]", ignore_case = TRUE)
    ),
    pa = ifelse(
      is.na(pa),
      str_extract(
        textes, regex("nommée\\s*(.*?)[\"]", ignore_case = TRUE)
      ),
      pa
    ),
    pa = ifelse(
      str_detect(textes, "respectivement"),
      str_extract(
        textes,
        regex("respectivement\\s+(.*?)(?=\\.|N°|ETAT)", ignore_case = TRUE)
      ),
      pa
    ),
    pa = str_replace(pa, "\"Complexe des Aires", "Complexe des Aires"), 
    pa = str_remove(pa, "^nommée\\s*"),  # Supprime "nommée"
    pa = str_remove(pa, "^respectivement\\s*"),  # Supprime "nommée"
    pa = str_remove(pa, "(?<=\")[^\"«]*$"),  # Supprime tout après le 2e guillemet
    pa = str_remove_all(pa, "[\"«»]"),  # Supprime les quotes
    pa = str_trim(pa),  # Supprime les espaces en trop
    pa = str_remove(pa, ",$"),
    pa = str_remove(pa, "^'"),
    .before = textes
  )
```

On matche le nom des aires protégés avec les noms SAPM

```{r}
library(stringdist)
library(fuzzyjoin)
sapm_2017 <- read_rds("data/sapm_2017.rds")



sapm_2017 %>%
  pluck("SHORT_NAME")

class_results %>%
  pluck("pa")

# Harmonization for comparison (without modifying original data)
sapm_clean <- sapm_2017 %>%
  mutate(cleaned_SHORT_NAME = str_trim(str_to_lower(SHORT_NAME)))

class_clean <- class_results %>%
  mutate(cleaned_pa = str_trim(str_to_lower(pa)))

# Split cells containing multiple names (both ", " and " et " as separators)
split_class_clean <- class_clean %>%
  mutate(cleaned_pa_split = str_split(cleaned_pa, ",\\s*|\\s+et\\s+")) %>%  # Split on commas or " et "
  unnest(cleaned_pa_split) %>%
  rename(single_cleaned_pa = cleaned_pa_split)  # Rename for clarity

# Function to compute proportional string distance
match_pa_to_sapm <- function(pa_name, sapm_names) {
  # Calculate proportional distances
  distances <- stringdist(
    a = pa_name,
    b = sapm_names,
    method = "lv"  # Levenshtein distance
  ) / pmax(nchar(pa_name), nchar(sapm_names))
  
  # Find the best match
  best_match_idx <- which.min(distances)
  list(
    closest_match = sapm_names[best_match_idx],
    match_distance = distances[best_match_idx]
  )
}

# Find closest matches for each split name
conversion_table <- split_class_clean %>%
  rowwise() %>%
  mutate(
    match_result = list(match_pa_to_sapm(single_cleaned_pa, sapm_clean$cleaned_SHORT_NAME)),
    closest_match = sapm_clean$SHORT_NAME[which.min(
      stringdist(single_cleaned_pa, sapm_clean$cleaned_SHORT_NAME) / 
        pmax(nchar(single_cleaned_pa), nchar(sapm_clean$cleaned_SHORT_NAME))
    )],
    match_distance = min(
      stringdist(single_cleaned_pa, sapm_clean$cleaned_SHORT_NAME) /
        pmax(nchar(single_cleaned_pa), nchar(sapm_clean$cleaned_SHORT_NAME))
    )
  ) %>%
  ungroup() %>%
  select(original_pa = single_cleaned_pa, closest_match, match_distance)


writexl::write_xlsx(conversion_table, "conversion_table.xlsx")


```

```{r}
library(geodata)
communes <- gadm("Madagascar", level = 4, path = "data") %>%
  st_as_sf()

ma_com <- communes %>%
  filter(NAME_4 == "Ambalabe" & NAME_2 == "Atsinanana")

tm_shape(sapm_2017)  +
  tm_fill() +
  tm_shape(ma_com) + 
  tm_borders(col = "red")

```
